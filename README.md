# Project2-DataAnalytics-ETL

ReadMe Introduction

Welcome to the ReadMe for our data analytics ETL project. This project was developed as part of a data analytics bootcamp and is designed to demonstrate the skills learned in extracting, transforming, and loading data from various sources into a target database or data warehouse.

In this ReadMe, we will provide an overview of the project goals and the analysis contained in this repository.

The goal of this project was to obtain at least two data files from a reliable source, ideally in .csv or .json file type. The data source we access was credit card application data used to predict the credit application approvals (宋骁 Seanny 2019).   We then used a combination of Postgres, Python, and other ETL frameworks to extract, transform, and load the data, while ensuring the accuracy and integrity of the resulting dataset.
Throughout the project, we worked closely as a team to design and implement the ETL process. Using Jupyter Notebooks to ensure code was executed correctly, and fix errors were appropriate.

This GitHub respository contains the Jupyter Notebook used to conduct the ETL, as well as a technical report that further details the analysis.
The original datasources can be found in the Resources folder within this respostiory.

Getting Started
These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

Prerequisites
Before you can run this project, you will need to have the following software installed on your machine:

Python 3
A modern web browser

You will also need to install the following Python packages:

pandas
sqlalchemy
datetime
timedelta

Contributions
This project was developed as part of a data analytics bootcamp and is not currently accepting contributions. However, we welcome any feedback or suggestions for improvement.
